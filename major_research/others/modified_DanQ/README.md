Implementation for full DanQ model

after removing grads_tot

Starting epochs : 1
loss : 19.6879
loss : 1.17567
loss : 1.0005
loss : 0.693164
loss : 0.693153
Starting epochs : 2
loss : 0.693153
loss : 0.693153
loss : 0.693153
loss : 0.693153
loss : 0.693153
Starting epochs : 3
loss : 0.693153
loss : 0.693153
loss : 0.693153
loss : 0.693153
loss : 0.693153
Starting epochs : 4
loss : 0.693153
loss : 0.693153
loss : 0.693153
loss : 0.693153

after modifyin

Starting epochs : 1
loss : 19.3113
loss : 2.07445
loss : 0.669312
loss : 0.693153
loss : 0.693153
Starting epochs : 2
loss : 0.693153
loss : 0.693153
loss : 0.693153
loss : 0.693153
loss : 0.693153

